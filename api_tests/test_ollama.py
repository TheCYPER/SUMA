#!/usr/bin/env python3
"""
Ollama è¿æ¥æµ‹è¯•è„šæœ¬
æµ‹è¯• Ollama æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
"""

import requests
import json
import sys

OLLAMA_BASE_URL = "http://localhost:11434"

def test_ollama_connection():
    """æµ‹è¯• Ollama è¿æ¥"""
    print("ğŸ” æµ‹è¯• Ollama è¿æ¥...")
    
    try:
        # æµ‹è¯•åŸºæœ¬è¿æ¥
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ")
            
            # è·å–å¯ç”¨æ¨¡å‹
            models = response.json()
            if 'models' in models and models['models']:
                print(f"ğŸ“¦ å¯ç”¨æ¨¡å‹: {len(models['models'])} ä¸ª")
                for model in models['models']:
                    print(f"   - {model['name']}")
            else:
                print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å·²ä¸‹è½½çš„æ¨¡å‹")
                print("   è¯·è¿è¡Œ: ollama pull llama3.2")
                return False
            
            return True
        else:
            print(f"âŒ Ollama æœåŠ¡å“åº”é”™è¯¯: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡")
        print("   è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ: ollama serve")
        return False
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_chat():
    """æµ‹è¯•æ¨¡å‹èŠå¤©åŠŸèƒ½"""
    print("\nğŸ¤– æµ‹è¯•æ¨¡å‹èŠå¤©åŠŸèƒ½...")
    
    try:
        # æµ‹è¯•èŠå¤© API
        chat_data = {
            "model": "llama3.1:8b",
            "messages": [
                {
                    "role": "user",
                    "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"
                }
            ],
            "stream": False
        }
        
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/chat",
            json=chat_data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'message' in result and 'content' in result['message']:
                print("âœ… æ¨¡å‹èŠå¤©åŠŸèƒ½æ­£å¸¸")
                print(f"   å›å¤: {result['message']['content'][:100]}...")
                return True
            else:
                print("âŒ æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                return False
        else:
            print(f"âŒ èŠå¤©æµ‹è¯•å¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ èŠå¤©æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Ollama è¿æ¥æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•è¿æ¥
    if not test_ollama_connection():
        print("\nâŒ Ollama è®¾ç½®ä¸å®Œæ•´")
        print("\nè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è®¾ç½® Ollama:")
        print("1. å®‰è£… Ollama: https://ollama.ai")
        print("2. å¯åŠ¨æœåŠ¡: ollama serve")
        print("3. ä¸‹è½½æ¨¡å‹: ollama pull llama3.2")
        sys.exit(1)
    
    # æµ‹è¯•èŠå¤©
    if not test_model_chat():
        print("\nâŒ æ¨¡å‹èŠå¤©åŠŸèƒ½å¼‚å¸¸")
        print("è¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®ä¸‹è½½")
        sys.exit(1)
    
    print("\nğŸ‰ Ollama è®¾ç½®å®Œæˆï¼")
    print("ç°åœ¨å¯ä»¥å¯åŠ¨ SUMA LMS å¹¶ä½¿ç”¨ AI åŠŸèƒ½äº†")
    print("\nå¯åŠ¨å‘½ä»¤:")
    print("python3 -m app.main")

if __name__ == "__main__":
    main()
